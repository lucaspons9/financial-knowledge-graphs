openai:
  api_key: ${OPENAI_API_KEY}
  full_model: "gpt-4o"
  light_model: "gpt-4o-mini"
  temperature: 0.7

# SiliconFlow DeepSeek models
siliconflow:
  api_key: ${SILICONFLOW_API_KEY}
  full_model: "DeepSeek-V3"
  light_model: "DeepSeek-Coder-V2-Instruct"
  temperature: 0.7
  max_tokens: 2048
  top_p: 0.7
  frequency_penalty: 0.5

# Llama models via Ollama
llama3:
  light_model: "llama3:8b"
  full_model: "llama3:8b-instruct"
  temperature: 0.1
  max_tokens: 1024

# T5 models for information extraction
t5:
  light_model: "t5-large"
  full_model: "t5-3B"
  temperature: 0.1
  max_length: 128
# anthropic:
#   api_key: ${ANTHROPIC_API_KEY}
#   full_model: "claude-2"
#   light_model: "claude-instant-1"
#   temperature: 0.6

# cohere:
#   api_key: ${COHERE_API_KEY}
#   full_model: "command-r"
#   light_model: "command-light"
#   temperature: 0.5

# mistral:
#   api_key: ${MISTRAL_API_KEY}
#   full_model: "mistral-7b"
#   light_model: "mistral-small"
#   temperature: 0.7
