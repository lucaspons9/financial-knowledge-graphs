llm_provider: "openai" # Change this to "anthropic", "cohere", "mistral", "local"
mode: "light" # Options: "full" for high-quality, "light" for efficiency
task: "entity_extraction"


models_path: "models.yaml" # Path to the models configuration file
prompt_path: "prompts/prompts.yaml" # Path to the prompt YAML file chosen
